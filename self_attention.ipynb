{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9d175311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Transformer-From-Scratch\\venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:283: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from typing import List\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ddd4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=requests.get(\"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa2982e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b70ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71d8307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffc1b8a",
   "metadata": {},
   "source": [
    "### voacb/tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9760c4",
   "metadata": {},
   "source": [
    "We will build basic tokenization as of now which will be of character based tokenization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b59de",
   "metadata": {},
   "source": [
    "##### tiktoken\n",
    "\n",
    "This also can be used to tokenize. I mean we don't have to worry about tokenization stuff\n",
    "\n",
    "```py\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\") # this download the encoding used for gpt-4o model\n",
    "enc.encode(\"hello world \")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "667f446e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text)) # we have all the characters here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68417260",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index={char:index for index,char in enumerate(sorted(set(text)))}\n",
    "index_to_char={index:char for index,char in enumerate(sorted(set(text)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "933586f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(index_to_char[2])\n",
    "print(char_to_index['!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0be87dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "word='hello world'\n",
    "def encode(sent:str)->List[int]:\n",
    "    outpur_seq=[]\n",
    "    for char in sent:\n",
    "        outpur_seq.append(char_to_index[char])\n",
    "    return outpur_seq\n",
    "    \n",
    "\n",
    "def decode(seq:List[int])->str:\n",
    "    output_seq=\"\"\n",
    "    for index in seq:\n",
    "        output_seq+=index_to_char[index]\n",
    "    \n",
    "    return output_seq\n",
    "\n",
    "print(encode(word))\n",
    "print(decode([46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "41837955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the text\n",
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "abaf6cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "        53, 56])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30132b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5522b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7752988",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ddbe63e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04ddb726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24912, 2375, 220]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\") # this download the encoding used for gpt-4o model\n",
    "enc.encode(\"hello world \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed97821e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 16715, 45670, 19, 10029]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode('4bcgc4bb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3af7e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ful\n",
      " dif\n",
      "til\n",
      "na\n",
      " were\n",
      "ہ\n",
      " ع\n",
      "'t\n",
      ".h\n",
      "####\n",
      "ople\n",
      " into\n",
      " sur\n",
      "ows\n",
      " Tr\n",
      "amp\n",
      " De\n",
      "air\n",
      " {\n",
      "\n",
      " cre\n",
      " make\n",
      "rol\n",
      "ina\n",
      "от\n",
      "ta\n",
      " א\n",
      "(f\n",
      "ու\n",
      "�\n",
      "SE\n",
      "્\n",
      "ے\n",
      " Con\n",
      "ु\n",
      " result\n",
      "_b\n",
      " rel\n",
      "_id\n",
      "ات\n",
      " loc\n",
      "\">\n",
      "\n",
      "ics\n",
      "')\n",
      " sub\n",
      "error\n",
      "ethod\n",
      " )\n",
      "ze\n",
      " fl\n",
      "ી\n",
      " Se\n",
      "========\n",
      "્�\n",
      "af\n",
      "ह\n",
      "ho\n",
      "�\n",
      " java\n",
      "ody\n",
      " म\n",
      "ml\n",
      "ts\n",
      " list\n",
      "�\n",
      "ins\n",
      "_d\n",
      "ww\n",
      "ת\n",
      "En\n",
      "ా\n",
      "מ\n",
      "�\n",
      " than\n",
      "’t\n",
      "ем\n",
      "itle\n",
      "ente\n",
      " first\n",
      "ica\n",
      " aw\n",
      "ę\n",
      " bo\n",
      "By\n",
      " प\n",
      "Se\n",
      "–\n",
      "Par\n",
      "je\n",
      " import\n",
      " tem\n",
      "Item\n",
      "ു\n",
      "]\n",
      "\n",
      " س\n",
      "value\n",
      "ious\n",
      "work\n",
      "ause\n",
      "print\n",
      "ка\n",
      "lick\n",
      "ule\n",
      " back\n",
      "ense\n",
      " start\n",
      " ein\n",
      " only\n",
      "(\n",
      "\n",
      " You\n",
      "ures\n",
      " ke\n",
      "ower\n",
      "**\n",
      "\n",
      "****************\n",
      "arr\n",
      "�\n",
      "的\n",
      " its\n",
      "raw\n",
      "ร\n",
      " fil\n",
      " string\n",
      "ces\n",
      " inform\n",
      "ą\n",
      " form\n",
      "ments\n",
      "ү\n",
      "urs\n",
      "ities\n",
      "ayer\n",
      " look\n",
      " let\n",
      " static\n",
      "ember\n",
      "day\n",
      " best\n",
      "म\n",
      "Value\n",
      "ler\n",
      "大\n",
      " under\n",
      "ు\n",
      " trans\n",
      "ender\n",
      " most\n",
      " find\n",
      " person\n",
      " ed\n",
      "ustom\n",
      "ла\n",
      "].\n",
      " help\n",
      "olog\n",
      "ки\n",
      "string\n",
      " Wh\n",
      " ng\n",
      "ateg\n",
      "lection\n",
      "den\n",
      "oth\n",
      " rem\n",
      "ا�\n",
      "κ\n",
      " people\n",
      " !=\n",
      " Al\n",
      "أ\n",
      " car\n",
      "।\n",
      "const\n",
      "ி\n",
      "ọ\n",
      "ാ\n",
      "la\n",
      "ಿ�\n",
      "ед\n",
      "ğ\n",
      " He\n",
      " ass\n",
      "irect\n",
      " want\n",
      "ari\n",
      "://\n",
      "ession\n",
      "                           \n",
      "ren\n",
      "ան\n",
      " An\n",
      "ै\n",
      "ия\n",
      "bo\n",
      "={\n",
      "ு\n",
      "gram\n",
      ".D\n",
      "br\n",
      "             \n",
      "      \n",
      " don\n",
      " long\n",
      "он\n",
      "!\n",
      "\n",
      "\n",
      " gu\n",
      " sk\n",
      "ern\n",
      "Im\n",
      "wa\n",
      "22\n",
      " inst\n",
      "load\n",
      "rough\n",
      " um\n",
      "�\n",
      "?\n",
      "\n",
      "\n",
      "ha\n",
      "щ\n",
      " أ\n",
      "ets\n",
      "_C\n",
      " final\n",
      "μ\n",
      "40\n",
      " arr\n",
      " &&\n",
      "ב\n",
      "λ\n",
      "时\n",
      " read\n",
      "ë\n",
      "ש\n",
      "อ\n",
      "orld\n",
      "uc\n",
      "];\n",
      "\n",
      "hed\n",
      ".F\n",
      "reak\n",
      "fr\n",
      "atus\n",
      " ge\n",
      "ой\n",
      " ve\n",
      "ting\n",
      "';\n",
      "\n",
      " test\n",
      "ção\n",
      "++\n",
      "�\n",
      "no\n",
      "bl\n",
      "Object\n",
      " every\n",
      " Ar\n",
      " spec\n",
      "és\n",
      " should\n",
      "ponent\n",
      "ES\n",
      ".j\n",
      " know\n",
      "ood\n",
      "ility\n",
      "Exception\n",
      " sm\n",
      "נ\n",
      " mon\n",
      "[i\n",
      " cr\n",
      " she\n",
      " Ex\n",
      "wn\n",
      "\tpublic\n",
      " �\n",
      " well\n",
      "ush\n",
      "ż\n",
      "ux\n",
      " �\n",
      " pres\n",
      " sch\n",
      "ms\n",
      "да\n",
      " si\n",
      "yp\n",
      " den\n",
      "tra\n",
      "iver\n",
      "ാ�\n",
      "ager\n",
      " ن\n",
      "ಾ\n",
      " il\n",
      " exper\n",
      "ө\n",
      " som\n",
      " �\n",
      "col\n",
      "ative\n"
     ]
    }
   ],
   "source": [
    "for i in range(1500,1800):\n",
    "    print(enc.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f57d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1544d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b7b1c0e",
   "metadata": {},
   "source": [
    "Im not a writer and has nopt written anything before. So this content is raw with minimal amount of technical jargons and i tried to explain things in easiest possible way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9790863",
   "metadata": {},
   "source": [
    "# Self Attention\n",
    "\n",
    "Why - \n",
    "\n",
    "What - \n",
    "\n",
    "How - \n",
    "\n",
    "\n",
    "See when we create vector embeddings using word2vec we get the static embeding means that embeding try to capture the avg meaning of the sentecnce. But it is not good way to create them. The most commong example for this i want to recite from the book called \" Hands on largge langusga emodel by jay Alammar & Marrteen Grootendorst O'relly publication is river bank and money bank. So here bank means two diff things and if we use static embeding to represent the word that would lead to missunderstanding. So we have to solve this problem by generating dynamic embeding which can have the contect of surrounding words as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3caf71",
   "metadata": {},
   "source": [
    "Question is how we do that- \n",
    "\n",
    "Simplest possible asnwer is take into account the static embedings of surrounding words or the words in that sequence. And by that we mean just have the weighted sum of all the embedings. by doing that we can can caputure the dynamic meaning of the word. \n",
    "\n",
    "But next quesion is what those weight will be like how can we calculate those weights. \n",
    "\n",
    "One thought could be why not calculating the similarity between the main word and the context/neighbour words. \n",
    "\n",
    "Lets try to implement this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77e8738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 430.57it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\") # this may occupy some space in local storage \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039f3c8",
   "metadata": {},
   "source": [
    "****************\n",
    "So to implement this I'll be using  2 sentences\n",
    "\n",
    "1. The fisherman sat quietly on the bank of the river watching the water flow. - rletaed to river bank \n",
    "2. She visited the bank to deposit her salary into her savings account - related to money bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124813c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"River bank is calm\"\n",
    "sentence2 = \"Bank stores money\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88006d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets calculate the embedings of each word first  \n",
    "words1 = sentence1.split()\n",
    "words2 = sentence2.split()\n",
    "\n",
    "# Get embeddings for each word\n",
    "embeddings1 = {word: torch.from_numpy(model.encode(word)) for word in words1} #  # I'll be using pytorch for mathemetical ops\n",
    "embeddings2 = {word: torch.from_numpy(model.encode(word)) for word in words2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "962a85ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4996, 1.0000, 0.2495, 0.2183])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I'll calculate the dot product of all the embedings of first sentence with the word bank and get the score/weight \n",
    "weights1 = torch.tensor([\n",
    "    torch.dot(embeddings1['bank'], embeddings1[word])\n",
    "    for word in embeddings1\n",
    "])\n",
    "\n",
    "weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98cf09d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2391, 0.3943, 0.1862, 0.1804])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To normalize the weights lets apply softmax\n",
    "weights1 = torch.softmax(weights1, dim=0)\n",
    "weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf28f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply these weights with embeding vectors of all the words in sentence 1\n",
    "embedding_matrix = torch.stack([embeddings1[word] for word in embeddings1]) # 4*384 - coz we have 4 unique words in sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd205447",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_bank1 = torch.matmul(weights1, embedding_matrix) # this is now new embeding of the word bank in context with sentence1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9978c0",
   "metadata": {},
   "source": [
    "And now if we calculate the dot product of this with the word river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22ae359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Similarity score between River and bank :  tensor(0.4996)\n",
      "new Similarity score between River and bank :  tensor(0.5381)\n"
     ]
    }
   ],
   "source": [
    "print(\"Old Similarity score between River and bank : \",torch.dot(embeddings1['River'],embeddings1['bank']))\n",
    "print(\"new Similarity score between River and bank : \",torch.dot(embeddings1['River'],e_bank1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e0c065",
   "metadata": {},
   "source": [
    "See we have increased the similarity between river and bank by doing this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68447404",
   "metadata": {},
   "source": [
    "Now lets do the same for second sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60bdb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I'll calculate the dot product of all the embedings of first sentence with the word bank and get the score/weight \n",
    "weights2 = torch.tensor([\n",
    "    torch.dot(embeddings2['Bank'], embeddings2[word])\n",
    "    for word in embeddings2\n",
    "])\n",
    "weights2 = torch.softmax(weights2, dim=0)\n",
    "\n",
    "embedding_matrix_2 = torch.stack([embeddings2[word] for word in embeddings2]) # 12*384 - coz we have 12 unique words in sent1\n",
    "\n",
    "e_bank2 = torch.matmul(weights2, embedding_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0e7e5347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Similarity score between Money and bank :  tensor(0.4690)\n",
      "new Similarity score between Money and bank :  tensor(0.5875)\n"
     ]
    }
   ],
   "source": [
    "print(\"Old Similarity score between Money and bank : \",torch.dot(embeddings2['money'],embeddings2['Bank']))\n",
    "print(\"new Similarity score between Money and bank : \",torch.dot(embeddings2['money'],e_bank2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea291f79",
   "metadata": {},
   "source": [
    "Here also similarity is increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04534080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16b46724",
   "metadata": {},
   "source": [
    "### Issues with this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2e9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
